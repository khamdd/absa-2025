{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927e5451-85ca-4b6d-9007-927c17a2ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow\n",
    "!pip install -q datasets\n",
    "!pip install -q accelerate\n",
    "!pip install -q transformers\n",
    "!pip install -q emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450590b5-ab8e-4b08-957c-aa0d6412cdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.19.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "sys.path.append('..')\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be075d-8012-400f-883d-80f707301099",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print('Using GPU:', tf.test.gpu_device_name())\n",
    "    !nvcc -V\n",
    "else: raise ValueError('Running on CPU is not recommended.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/khamdd/absa-2025\n",
    "%cd ./absa-2025\n",
    "!mkdir predictions\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d6986d-ae18-4962-a6da-9930a395a3d8",
   "metadata": {},
   "source": [
    "# Constants Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd34603-4f11-4140-9a70-e5355e892e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../datasets/eval_2014/Restaurants_Train_v2.xml'\n",
    "PREPROCESSED_TRAIN_PATH = '../datasets/eval_2014/Restaurants_Train_v2.csv'\n",
    "PRETRAINED_MODEL = 'bert-base-uncased'\n",
    "MODEL_NAME = \"Restaurant-v1\"\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 21\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09b3254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated:../datasets/eval_2014/Restaurants_Train_v2.csv\n"
     ]
    }
   ],
   "source": [
    "from processors.eval2014_processor import Eval2014Loader\n",
    "\n",
    "Eval2014Loader.xmlToCSV(TRAIN_PATH, PREPROCESSED_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e311bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61787b98247144549bcdaa3c2537e58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Review', 'ambience', 'anecdotes/miscellaneous', 'food', 'price', 'service'],\n",
       "        num_rows: 3041\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = Eval2014Loader.load(PREPROCESSED_TRAIN_PATH)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89ab0c",
   "metadata": {},
   "source": [
    "# Preprocess and Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92feeb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dangd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dangd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dangd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from processors.english_processor import EnglishTextPreprocessor\n",
    "\n",
    "eng_preprocessor = EnglishTextPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87fa17e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode: [101, 2023, 2003, 1037, 8285, 19204, 17629, 3231, 5164, 102] \n",
      "Decode: [CLS] this is a auto tokenizer test string [SEP]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "tokens = tokenizer.encode(\"This is a auto tokenizer test string\")\n",
    "print('Encode:', tokens, '\\nDecode:', tokenizer.decode(tokens))\n",
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd039a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tokenizing text data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a546342b46614752b8085c35ad3adf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8420a40d4a7f43e0a25cb34deae0f5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ambience', 'anecdotes/miscellaneous', 'food', 'price', 'service', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3041\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_datasets</th>\n",
       "      <th>encoded_input_ids</th>\n",
       "      <th>decoded_input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>[101, 2021, 1996, 3095, 2001, 2061, 9202, 2000...</td>\n",
       "      <td>[CLS] but the staff was so horrible to us. [SE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>[101, 2000, 2022, 3294, 4189, 1010, 1996, 2069...</td>\n",
       "      <td>[CLS] to be completely fair, the only redeemin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>[101, 1996, 2833, 2003, 27423, 11813, 1010, 20...</td>\n",
       "      <td>[CLS] the food is uniformly exceptional, with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>[101, 2073, 6127, 2050, 3167, 2100, 17021, 201...</td>\n",
       "      <td>[CLS] where gabriela personaly greets you and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For those that go once and don't enjoy it, all...</td>\n",
       "      <td>[101, 2005, 2216, 2008, 2175, 2320, 1998, 2123...</td>\n",
       "      <td>[CLS] for those that go once and don ' t enjoy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Not only was the food outstanding, but the lit...</td>\n",
       "      <td>[101, 2025, 2069, 2001, 1996, 2833, 5151, 1010...</td>\n",
       "      <td>[CLS] not only was the food outstanding, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>It is very overpriced and not very tasty.</td>\n",
       "      <td>[101, 2009, 2003, 2200, 2058, 18098, 6610, 209...</td>\n",
       "      <td>[CLS] it is very overpriced and not very tasty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Our agreed favorite is the orrechiete with sau...</td>\n",
       "      <td>[101, 2256, 3530, 5440, 2003, 1996, 26914, 159...</td>\n",
       "      <td>[CLS] our agreed favorite is the orrechiete wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Bagels have an outstanding taste with a te...</td>\n",
       "      <td>[101, 1996, 4524, 9050, 2031, 2019, 5151, 5510...</td>\n",
       "      <td>[CLS] the bagels have an outstanding taste wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nevertheless the food itself is pretty good.</td>\n",
       "      <td>[101, 6600, 1996, 2833, 2993, 2003, 3492, 2204...</td>\n",
       "      <td>[CLS] nevertheless the food itself is pretty g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        raw_datasets  \\\n",
       "0               But the staff was so horrible to us.   \n",
       "1  To be completely fair, the only redeeming fact...   \n",
       "2  The food is uniformly exceptional, with a very...   \n",
       "3  Where Gabriela personaly greets you and recomm...   \n",
       "4  For those that go once and don't enjoy it, all...   \n",
       "5  Not only was the food outstanding, but the lit...   \n",
       "6          It is very overpriced and not very tasty.   \n",
       "7  Our agreed favorite is the orrechiete with sau...   \n",
       "8  The Bagels have an outstanding taste with a te...   \n",
       "9       Nevertheless the food itself is pretty good.   \n",
       "\n",
       "                                   encoded_input_ids  \\\n",
       "0  [101, 2021, 1996, 3095, 2001, 2061, 9202, 2000...   \n",
       "1  [101, 2000, 2022, 3294, 4189, 1010, 1996, 2069...   \n",
       "2  [101, 1996, 2833, 2003, 27423, 11813, 1010, 20...   \n",
       "3  [101, 2073, 6127, 2050, 3167, 2100, 17021, 201...   \n",
       "4  [101, 2005, 2216, 2008, 2175, 2320, 1998, 2123...   \n",
       "5  [101, 2025, 2069, 2001, 1996, 2833, 5151, 1010...   \n",
       "6  [101, 2009, 2003, 2200, 2058, 18098, 6610, 209...   \n",
       "7  [101, 2256, 3530, 5440, 2003, 1996, 26914, 159...   \n",
       "8  [101, 1996, 4524, 9050, 2031, 2019, 5151, 5510...   \n",
       "9  [101, 6600, 1996, 2833, 2993, 2003, 3492, 2204...   \n",
       "\n",
       "                                   decoded_input_ids  \n",
       "0  [CLS] but the staff was so horrible to us. [SE...  \n",
       "1  [CLS] to be completely fair, the only redeemin...  \n",
       "2  [CLS] the food is uniformly exceptional, with ...  \n",
       "3  [CLS] where gabriela personaly greets you and ...  \n",
       "4  [CLS] for those that go once and don ' t enjoy...  \n",
       "5  [CLS] not only was the food outstanding, but t...  \n",
       "6  [CLS] it is very overpriced and not very tasty...  \n",
       "7  [CLS] our agreed favorite is the orrechiete wi...  \n",
       "8  [CLS] the bagels have an outstanding taste wit...  \n",
       "9  [CLS] nevertheless the food itself is pretty g...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_datasets = Eval2014Loader.preprocess_and_tokenize(raw_datasets, eng_preprocessor, tokenizer, BATCH_SIZE * 2, MAX_LENGTH)\n",
    "preprocessed_datasets.save_to_disk('../datasets/preprocessed_restaurant')\n",
    "display(preprocessed_datasets)\n",
    "pd.DataFrame({\n",
    "    'raw_datasets': raw_datasets['train']['Review'][:10],\n",
    "    'encoded_input_ids': preprocessed_datasets['train']['input_ids'][:10],\n",
    "    'decoded_input_ids': [tokenizer.decode(preprocessed_datasets['train'][i]['input_ids']) for i in range(10)]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231bd61-527b-404a-a53d-54407d17c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "preprocessed_datasets = load_from_disk('../datasets/preprocessed_restaurant')\n",
    "preprocessed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c3402-ce05-4024-b030-46b1340fd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Categories\n",
    "\n",
    "categories = df['category'].unique()\n",
    "\n",
    "categories = categories.tolist()\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93844c-83a3-49fa-aa59-6857eacb1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityMapping:\n",
    "    INDEX_TO_POLARITY = {0: None, 1: 'positive', 2: 'negative', 3: 'neutral'}\n",
    "    INDEX_TO_ONEHOT = {0: [1, 0, 0, 0], 1: [0, 1, 0, 0], 2: [0, 0, 1, 0], 3: [0, 0, 0, 1]}\n",
    "    POLARITY_TO_INDEX = {None: 0, 'positive': 1, 'negative': 2, 'neutral': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5590972-c86c-44d6-a009-0ffe3d7ec0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "def preprocess_and_tokenize(data, tokenizer, max_length=128, batch_size=32):\n",
    "    print(\"[INFO] Preprocessing and tokenizing data...\")\n",
    "\n",
    "    def process_batch(batch):\n",
    "        sentences = [item[\"sentence\"] for item in batch]\n",
    "        labels = [item[\"label\"] for item in batch]\n",
    "\n",
    "        # Tokenize sentences\n",
    "        tokenized = tokenizer(\n",
    "            sentences,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=None\n",
    "        )\n",
    "\n",
    "        # Add one-hot encoded labels\n",
    "        tokenized[\"FlattenOneHotLabels\"] = [\n",
    "            PolarityMapping.INDEX_TO_ONEHOT[label] for label in labels\n",
    "        ]\n",
    "        return tokenized\n",
    "\n",
    "    tokenized_data = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"FlattenOneHotLabels\": []\n",
    "    }\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        tokenized_batch = process_batch(batch)\n",
    "        tokenized_data[\"input_ids\"].extend(tokenized_batch[\"input_ids\"])\n",
    "        tokenized_data[\"attention_mask\"].extend(tokenized_batch[\"attention_mask\"])\n",
    "        tokenized_data[\"FlattenOneHotLabels\"].extend(tokenized_batch[\"FlattenOneHotLabels\"])\n",
    "\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sentence in root.iter(\"sentence\"):\n",
    "    text = sentence.find(\"text\").text\n",
    "    aspect_categories = sentence.find(\"aspectCategories\")\n",
    "    if aspect_categories is not None:\n",
    "        for category in aspect_categories.findall(\"aspectCategory\"):\n",
    "            polarity = category.attrib[\"polarity\"]\n",
    "            if polarity != \"conflict\":\n",
    "                data.append({\n",
    "                    \"sentence\": text,\n",
    "                    \"label\": PolarityMapping.POLARITY_TO_INDEX[polarity]\n",
    "                })\n",
    "\n",
    "# Preprocess and tokenize\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 128\n",
    "tokenized_data = preprocess_and_tokenize(data, tokenizer, max_length=MAX_LENGTH, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Save to disk\n",
    "output_path = ''\n",
    "pd.DataFrame(tokenized_data).to_csv(f\"{output_path}.csv\", index=False)\n",
    "\n",
    "# Display a sample\n",
    "sample_df = pd.DataFrame({\n",
    "    'raw_sentence': [item[\"sentence\"] for item in data[:10]],\n",
    "    'encoded_input_ids': tokenized_data[\"input_ids\"][:10],\n",
    "    'decoded_input_ids': [tokenizer.decode(ids) for ids in tokenized_data[\"input_ids\"][:10]],\n",
    "    'FlattenOneHotLabels': tokenized_data[\"FlattenOneHotLabels\"][:10]\n",
    "})\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cab059",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASPECT_CATEGORY_NAMES = df['category'].unique().tolist()\n",
    "steps_per_epoch = len(tokenized_data['input_ids']) // BATCH_SIZE\n",
    "total_steps = EPOCHS * steps_per_epoch\n",
    "print(ASPECT_CATEGORY_NAMES)\n",
    "print(\"Steps per epoch:\", steps_per_epoch)\n",
    "print(\"Total steps:\", total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5b396-7a0c-4aff-aad9-fc3683a75928",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a295c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "optimizer = Adam(learning_rate=CosineDecay(\n",
    "    initial_learning_rate = 1e-4,\n",
    "    warmup_target = 2e-4,\n",
    "    warmup_steps = int(total_steps * 0.15), # 15% of total_steps\n",
    "    decay_steps = int(total_steps * 0.3), # Next 30% of total_steps\n",
    "    alpha = 0.1, # Minimum lr for decay as a fraction of initial_learning_rate\n",
    "))\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience = 3, # Stop if no improvement after 3 epochs\n",
    "    restore_best_weights = True, # You may obtain HIGHER metrics on the test set with longer training time if you set this to False\n",
    "    # Because after some experiments, I found that even with higher val_loss, it still results in better metric reports on the test set. \n",
    "    # This maybe because the training set and the test set have more similarities than the validation data.\n",
    "    # But I think this is not fair, as we already have prior knowledge about the test set and we modified our training based on the performance on this set. \n",
    "    # In real-world, we should only modify our training based on the performance on the validation data\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from acsa_model import VLSP2018MultiTask\n",
    "from helper import plot_training_history\n",
    "model = VLSP2018MultiTask(PRETRAINED_MODEL, ASPECT_CATEGORY_NAMES, optimizer, name=MODEL_NAME)\n",
    "\n",
    "history = model.fit(\n",
    "    train_tf_dataset,\n",
    "    validation_data = val_tf_dataset,\n",
    "    callbacks = [early_stop_callback],\n",
    "    epochs = EPOCHS,\n",
    "    verbose = 1\n",
    ").history\n",
    "\n",
    "model.save_weights(f'./weights/{MODEL_NAME}/{MODEL_NAME}', save_format='tf')\n",
    "plot_training_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
